# SOMANet
Semantic-Orthogonal Multi-modal Attention Network for RGB-D Salient Object Detection
This is an official implementation for “Semantic-Orthogonal Multi-modal Attention Network for RGB-D Salient Object Detection”


Jiawei Xu,Qiangqiang Zhou,Jiacong Yu,Cheng Liao,Dandan ZHU


Environmental Setups
Pytorch ≥ 1.6.0, Torchvision ≥0.7.0

Data Preparation
 RGB-D SOD, we employ the following datasets to train the training sets of NJUD, NLPR, and DUTLF-Depth,while STERE, NJUD, NLPR, DUTLF-Depth, SIP, LFSD, RGBD135, SSD and ReDWeb-S datasets are employed for testing the RGB-D SOD task.You can directly download these datasets by following: https://pan.baidu.com/s/1yuqpXDuVt6IM0k5OTUQIDA 提取码: yqj9.


RGB-T SOD, we employ the following datasets to VT821,VT1000,VT50000.You can directly download these datasets by following:https://pan.baidu.com/s/1ri83cKHnyn7_9ptbLjWbow 提取码: 3vn8.

Experiments:
 First, you should choose the specific backbone version. For the swin version, we provide Swin-DESS(S) and Swin-DESS(B).

 Next, you should run test.py or train.py.

 If you have any questions or would like to know more details, please feel free to contact me.
 E-mail：Java_Xu1029@163.com,786857622@qq.com


Result:
![image](https://github.com/user-attachments/assets/137977bd-dba9-43c5-8fe5-79e8a12a4efb)

![image](https://github.com/user-attachments/assets/ed92bba8-c2f5-4ba0-aa48-316ac8474b25)


![image](https://github.com/user-attachments/assets/065e06ea-5ed2-4f79-bfdb-221f51d2cc87)




